<!DOCTYPE html>

<head>
    <link rel="stylesheet" type="text/css" href="paper.css">
    <title>HTTP 2 explained</title>
</head>

<body>
    <!-- Side navigation -->
    <div class="sidenav">
        <a href="#TODO">0. TODO</a>
        <a href="#what_is_http">1. Какво е HTTP?</a>
        <a href="#flaws_of_http1x">2. Недостатъците на HTTP/1.x</a>
        <a href="#what_is_http2">3. Какво е HTTP/2?</a>
        <a href="#binary_framing_layer">4. Binary framing layer</a>
        <a href="#streams_messages_frames">5. Streams, messages, and frames</a>
        <a href="#request_response_multiplexing">6. Request and response multiplexing</a>
        <a href="#stream_prioritization">7. Stream prioritization</a>
        <a href="#one_tcp_connection_per_origin">8. One TCP connection per origin</a>
        <a href="#flow_control">9.Flow control</a>
        <a href="#server_push">10. Server push</a>
        <a href="#push_promise_101">11. PUSH_PROMISE 101</a>
        <a href="#header_compression">12. Header compression</a>
        <a href="#resources">Resources</a>
    </div>

    <div class="main">
        <h1 id="TODO">0. НЕЩА, КОИТО ДА ДОВЪРША</h2>
            <ol>
                <li>
                    Да подобря структурата на изреченията и използваните думи, защото със сигурност има места, на които
                    информацията не е представена по най-добрия начин
                </li>
                <li>
                    Да сложа всички използвани ресурси в списъка, ако съм пропуснал някой
                </li>
                <li>
                    Да напиша точка 12. Header compression
                </li>
                <li>
                    Може би да подобря малко side-bar navigation-а, да се скрива и показва с javascript
                </li>
                <li>
                    Евентуално да сложа цветове и украси за естетика :D
                </li>
            </ol>

            <h1 id="what_is_http">1. Какво е HTTP? </h1>

            <img src="images/HTTP-Protocol.png" alt="HTTP request and response">

            <p>HTTP е мрежов протокол от приложния слой на OSI модела, служещ за обмяна на информация и ресурси в
                компютърни
                мрежи. Доказва се като много успешен през годините. С времето обаче се оказва, че начинът, по който
                по-старите
                версии на HTTP (1.0, 1.1) използват транспортния слой под себе си, е неефикасен и не отговаря на нуждите
                на
                модерния свят. Казано по-просто, мрежата, по която се пренасят HTTP съобщенията се натоварва излишно
                много и
                това води до проблеми.
            </p>

            <h1 id="flaws_of_http1x">2. Какви всъщност са недостатъците на HTTP/1.1 и HTTP/1.0? </h1>

            <p>За да бъда по-конкретен, нека да се върнем малко в историята.<br>
                Първите версии на HTTP са били създадени, търсейки простота. За жалост, тази простота е била за сметка
                на
                производителността на приложенията. Какви всъщост са проблемите?
            </p>

            <ul>
                <li>HTTP/1.0 позволява само и единствено една заявка да преминава през изградена TCP конекция. Това
                    очевидно
                    струва доста скъпо - всеки път, когато изпращаме заявка, трябва да преминаваме през изграждане на
                    TCP
                    връзка
                    - т.нар. three-way handshake. <br>
                    HTTP/1.1 частично се справи с този проблем чрез <b><a
                            href="https://en.wikipedia.org/wiki/HTTP_pipelining">HTTP pipelining</a></b>. Накратко това
                    ни
                    позволява да изпращаме
                    няколко заявки през една и съща TCP конекция (както се вижда на втората снимка - заявката на
                    HTTP/1.1
                    изисква снимка на къщата и колата, преди да се сложи край на конекцията). Все още обаче го има
                    проблема
                    с
                    <b><a href="https://en.wikipedia.org/wiki/Head-of-line_blocking">Head-of-line blocking (HOL
                            blocking)</a></b>.

                    <p>
                        Заради това клиентите, използващи HTTP/1.x, които искат да изпращат <b>много</b> заявки към
                        даден сървър, са принудени да изграждат няколко TCP конекции към сървъра, за да постигнат
                        конкурентност
                        на заявките (търсейки намаляване на <a href="http://www.linfo.org/latency.html">латенцията</a>).
                    </p>
                </li>

                <img src="images/http2-changes-everything-4-638.jpg" alt="HTTP: 1.1 vs 1.0" height="450" width="650">
                <img src="images/http2-changes-everything-5-638.jpg" alt="HTTP: 1.1 vs 1.0" height="450" width="650">

                <li>
                    HTTP хедърите (header fields) доста често са многословни и повтарящи се, което причинява ненужно
                    натоварване на мрежовия трафик, както и препълване на т.нар.
                    <a href="https://en.wikipedia.org/wiki/TCP_congestion_control#Congestion_window">TCP congestion
                        window</a> доста бързо.
                </li>
            </ul>

            <p>
                Тези проблеми не са били фатални, но с времето уеб приложенията са започнали да разширяват обхвата си,
                да
                стават
                по-сложни, както и по-важни за нас, хората. По-този начин отежниха задачата на самите
                потребителите на уеба, както и на уеб разработчиците. Точно това се опитва да олекоти HTTP/2.
            </p>

            <p>
                HTTP/2 се справя с тези проблеми, без да променя семантиката на протокола. Просто оптимизира начина, по
                който
                съобщенията се пренасят по транспортния слой/мрежата. Оптимизаците включват <b>мултиплексиране</b> на
                заявки
                и
                отговори (requests and responses) в една TCP конекция посредством т.нар. <b>streams</b>, както и
                <b>приоритизирането</b> на заявки - това позволява
                по-важните заявки да приключват по-бързо, което в крайна сметка подобрява производителността.
                <br><br>
                В крайна сметка HTTP/2 щади повече мрежата, защото се използват по-малко TCP конекции в сравнение с
                HTTP/1.x.

                Също така HTTP/2 обработва съобщенията по-ефикасно, използвайки т.нар. <b>binary framing layer</b>
            </p>

            <img src="images/http2-changes-everything-13-638.jpg" alt="HTTP timeline" height="450">

            <h1 id="what_is_http2">3. Какво е HTTP/2? </h1>

            <p>
                HTTP/2 е оптимизация на HTTP/1.1, позволяваща по-добро използване на мрежовите ресурси. Основната цел му
                е
                чрез
                нови способи за пренос на данни по мрежата, да се ускори времето за зареждане на дадена уеб страница.
                Предимствата на HTTP/2 са неща като по-добро управление на връзката, ниско потребление на трафик,
                бързодействие.
                Семантично по никакъв начин не се различава от HTTP/1.1. Всички основни концепции, като HTTP methods,
                status
                codes, URIs, headers fields, си остават същите.
                Разликата е в това как самите данни се форматират и пренасят между клиента и сървъра.
                <br>В резултат на това всички приложения, които
                използват HTTP/1.1 могат да преминат към HTTP/2 без модификации.

                <h2>Основни начини, по които HTTP 2 постига по-добра ефикасност:</h2>
                <ul>
                    <li>Request and response multiplexing in one TCP connection</li>
                    <li>Compression of HTTP header fields</li>
                    <li>Support for request prioritization</li>
                    <li>Server push</li>
                </ul>

                <p>За да могат да се имплементират изброените по-горе feature-и, са използвани много подобрения на самия
                    протокол - нов начин за flow control, error handling и upgrade mechanisms. Но гореописаните 4 неща
                    са
                    най-важните, които трябва да бъдат разбрани.
                </p>

            </p>

            <h1 id="binary_framing_layer">4. Binary framing layer</h1>

            <p>
                В основата на подобренията на HTTP 2 е споменатият по-горе <b>binary framing layer</b>, който определя
                как
                съобщенията
                се изграждат и трансферират между клиента и сървъра.
            </p>

            <img src="images/binary_framing_layer01.svg" alt="binary framing layer" height="350" width="700">

            <p>
                Думата "layer" (слой) се отнася до избора да се използва нов <b>механизъм за кодиране на съобщенията</b>
                между
                socket interface-а и
                HTTP API-то, с което нашите приложения работят. Семантиката на HTTP - verbs, methods и headers, не е
                засегната,
                но начинът, по който
                се кодира, докато се пренася по мрежата е различен. За разлика от HTTP/1.x, където имаме обикновен текст
                разделен с нови редове,
                всичката комуникация в HTTP/2 е разделена на по-малки messages и frames, като всяко от тях е кодирано в
                двоичен
                (binary) формат.
                <br><br>
                В резултат на този механизъм за кодиране, и клиентът, и сървърът трябва да 'знаят' и използват този
                механизъм,
                за да могат да се
                разбират. HTTP/1.x клиент няма да може да се разбере със сървър, поддържащ единствено HTTP/2, както и
                обратното.
                За щастие, нашите уеб
                приложения изобщо не е нужно да разбират за всички тези промени, тъй като HTTP клиентите и сървърите
                вършат
                работата 'зад завесите'.
            </p>

            <h1 id="streams_messages_frames">5. Streams, messages, and frames</h1>

            <p>
                Появата на <b>binary framing</b> механизма променя начина, по който данните меуду клиента и сървъра се
                обменят. За да опишем този процес, нека първо да се запознаем с HTTP/2 терминологията:
            </p>
            <ul>
                <li><b>Stream (поток)</b> - двупосочен поток от байтове в рамките на изградена връзка (TCP конекция), по
                    която може да преминават едно или няколко съобщения (messages).
                </li>
                <br>
                <li>
                    <b>Message (съобщение)</b> - поредица от <b>frames</b>, които в съвкупност образуват логическа
                    заявка или отговор (logical request or response message).
                </li>
                <br>
                <li>
                    <b>Frame</b> - най-малката 'комуникационна единица' в HTTP/2. Всеки <b>frame</b> съдържа т.нар.
                    <u>frame
                        header</u>,
                    който идентифицира stream-a, към който принадлежи.
                </li>
            </ul>
            <p>
                Връзката между тези термини може да се сумаризира по следния начин:<br><br>

                - Цялата комуникация между клиента и сървъра се извършва върху една TCP конекция, която има възможността
                да
                поддържа произволен брой двупосочни потоци (bidirectional streams).
                <br><br>
                - Всеки поток (stream) има уникален идентификатор и опционална информация, задаваща приоритета му,
                използвана за преноса на messages.
                <br><br>
                - Всеки message е логически HTTP message (request или response), което е съставено от един или няколко
                frame-a.
                <br><br>
                - Frame-ът е най-малката 'комуникационна единица', носеща със себе си специфични данни - например HTTP
                headers, message payload и т.н.
                Frame-ове, принадлежащи на <b>различни</b> потоци (streams), могат да бъдат 'преплетени' (interleaved) и
                впоследствие сглобени в
                съобщение, използвайки frame header за да се извлече информация към кой поток принадлежи.
            </p>

            <img src="images/streams_messages_frames01.svg" alt="streams, messages and frames" height="700"
                width="1000">

            <p>
                Накратко, HTTP/2 разбива комуникацията на HTTP протокола до обмен на <b>binary-encoded frames</b>, които
                сами по себе принадлежат на точно определен stream, и изграждат HTTP message. А всеки stream е
                мултиплексиран
                върху една и съща TCP конекция. Именно това стои в основата на всички други оптимизации, които HTTP/2
                предлага.
            </p>

            <h1 id="request_response_multiplexing">6. Request and response multiplexing</h1>

            <p>
                С HTTP/1.x, ако клиентът иска да направи няколко паралени заявки (request-и) към сървъра, няма друг
                избор освен изграждането на няколко TCP конекции. Това е така, заради
                HTTP/1.x <b>delivery model-ът</b>, който налага ограничението максимум един response да бъде доставян
                в даден момент (response queuing) в рамките на една TCP конекция. Още по-лошото е, че това довежда до
                вече
                споменатия HOL
                (head-of-line) blocking.
                Това е неефикасно използване на TCP конекцията.
                <br><br>
                Новият <b>binary framing layer</b> в HTTP/2 премахва тези ограничения и дава възможност
                напълно да се мултиплексират request-ите и respons-ите, позволявайки на клиентите и сървирте да разбиват
                HTTP съобщенията на независими един от друг frame-ове, след това да преплитат тези frame-ове и накрая да
                ги
                сглобяват обратно на другия край на конекцията.
            </p>

            <img src="images/multiplexing01.svg" alt="multiplexing" height="400" width="1000">

            <p>
                Снимката отгоре показва няколко потока (streams) в рамките на една TCP конекция. Клиентът изпраща DATA
                frame към сървъра, докато през това време сървърът препраща преплетена последователност от frames към
                клиента съответно за stream 1 и stream 3. В резултат на това получаваме 3 паралелни потока в действие.
                Способността да се разбие едно HTTP съобщение на независими frame-ове, след това да се преплитат и
                накрая да
                се сглобяват в съобщение е най-важното подобрение, което предлага HTTP/2. Ползите са много:
            </p>
            <ul>
                <li>
                    Паралелно изпращане на request-и без да се блокира нито един request.
                </li>
                <li>
                    Паралелно изпращане на response-и без да се блокира нито един response.
                </li>
                <li>
                    Използване на <b>една</b> TCP конекиця за доставяне на <b>няколко</b> request-и и respons-и в
                    паралел
                    (следствие от горните).
                </li>
                <li>
                    Премахване на HTTP/1.x <b>workarounds</b>, които имат за цел оптимизация на производителността (вече
                    не
                    са нужни!).
                </li>
                <li>
                    По-бързо зареждане на уеб страници, тъй като латенцията е по-малка. (използваме мрежовите
                    ресурси по ефикасно).
                </li>
                <li>
                    И много други...
                </li>
            </ul>
            <p>
                Накратко новият <b>binary framing layer</b> в HTTP/2 решава проблема с head-of-line blocking, който го
                има в
                HTTP/1.x и премахва нуждата от множество TCP конекции с цел изграждане на паралелна обработка на
                request-и и
                response-и. В резултат на това нашите приложения са по-прости, по-бързи и по-евтини за deployment
                (внедряване).
            </p>

            <h1 id="stream_prioritization">7. Stream prioritization</h1>

            <p>
                След като HTTP съобщението се раздели на индивидуални frame-ове, които принадлежат на различни
                strеам-ове и могат да се мултиплексират, има критично значение за производителността редът,
                по който ги 'преплитаме'. За да улесни този процес, HTTP/2 позволява всеки <b>stream</b> да има
                <b>weight (тежест)</b> и <b>dependency (зависимост)</b>.
            </p>

            <ul>
                <li>
                    Всеки stream може да има цяло число от 1 до 256, обозначаващо теглото му.
                </li>
                <li>
                    Всеки stream може да има експлицитна зависимост от друг stream.
                </li>
            </ul>
            </p>
            <p>
                Комбинацията от зависимости и тегла позволява на клиента да изгради и сподели
                <b>"дърво на зависимост (prioritization tree)"</b>,
                което казва как той би искал да получава response-ите. От своя страна сървърът може да използва тази
                информация с цел да приоритизира обработката на потоците, като контролира колко ресурси ще се заделят
                за даден поток (CPU, memory и др.). След като response-ът за даден поток е готов, сървърът
                настройва мрежата така, че да осигури оптимална доставка на response-и на <b>по-приоритетни</b> потоци
                към
                клиента.
            </p>

            <img src="images/stream_prioritization01.svg" alt="stream prioritization" height="400" width="1000">

            <p>
                <b>Stream dependency (зависимост между потоци)</b> в HTTP/2 се дефинира, като зависимият поток има
                <i>референция</i> към уникалния идентификатор на потока, от който зависи. Ако такава референция липсва,
                потокът по-подразбиране става зависим от т.нар. "root stream". Ако декларираме зависимост между потоци,
                това индикира, че за parent stream-ът ще бъдат заделяни ресурси по-рано, отколкото за child
                stream-овете.
                С други думи "Моля, обработете stream D преди stream C" (на картинката се вижда, че C е зависим от D).
                <br><br>

                За потоците, които имат един и същи баща (sibling streams), се заделят ресурси пропорционално на техните
                тегла.
                Например, ако поток А има тежест 12, а неговия брат B има тежест 4, тогава:
                <ol>
                    <li>
                        Сумираме теглата:
                        <code translate="no" dir="ltr">4 + 12 = 16</code>
                    </li>
                    <li>
                        Делим тежестта на всеки поток на сумата: A = 12/16, B= 4/16, т.е. А получава 3/4, а B получава
                        1/4
                        от наличните ресурси.
                    </li>
                </ol>
                <p>Да разгледаме примерите от снимката по-горе. От ляво на дясно:</p>
                <ol>
                    <li>
                        Нито поток А, нито поток B имат зависимост, за това имплицитно са зависими от "root stream".
                        Заради
                        това
                        гледаме теглата (както по-горе обяснихме, А получава 3/4, а B 1/4).
                    </li>
                    <li>
                        Поток D е зависим от "root stream". C е зависим от D. Така поток D трябва да получи 100% от
                        ресурсите преди поток C.
                        В случая тежестите нямат значение, понеже зависимостта на C играе по-силна роля от тежестта.
                    </li>
                    <li>
                        Поток D трябва да получи 100% от ресурсите преди поток C. C трябва да получи 100% от ресурсите
                        преди
                        A и B.
                        Поток B трябва да получи 1/3 от ресурсите спрямо поток А.
                    </li>
                    <li>
                        Поток D трябва да получи 100% от ресурсите преди потоците C и Е; Е и C трябва да получат
                        еднакакви
                        ресурси преди А и B; А и B трябва да получат ресурси пропорционални на теглата им.
                    </li>
                </ol>

                <p>
                    Както и горните примери показват, комбинацията между тегла и зависимости на потоците са добър и
                    експресивен начин да приоритизраме ресурсите, което е критично важно за производителността.
                    Също така HTTP/2 позволява на клиента да ъпдейтва тези предпочитания по всяко едно време, което
                    позволява да се правят още оптимизации в browser-a. С други думи, можем да променяме теглата и
                    зависимостите спрямо действията на потребителя, например.
                </p>

                <p class="note">
                    <strong>Забележка:</strong><span>
                        Зависимостите и теглата са <i>предпочитание</i> за транспрот, а не <i>изискване</i>.
                        Затова те не гарантират обработка или изпращане на ресурсите по определен ред. Тоест клиентът не
                        може да
                        'насили' сървъра да обработва потока по определен ред използвайки приоритета на самия поток.
                        Това може да звучи неинтуитивно, но всъщност е поведение, което желаем. Защото не искаме
                        сървърът да
                        блокира и да не прави никакъв прогрес върху ресурс с <b>по-нисък</b> приоритет, ако случайно
                        някой
                        ресурс с <b>по-висок</b> приоритет бъде блокиран.
                    </span>
                </p>
            </p>

            <h1 id="one_tcp_connection_per_origin">8. One TCP connection per origin</h1>

            <p>
                С новия <b>binary framing layer</b>, HTTP/2 няма нужда от изграждането на няколко TCP конекции.
                Както разбрахме, всеки stream бива 'преплетен' и приоритизиран. В резултат на това, всички HTTP/2
                конекции са постоянни (persistent) и само една конекция от дадена изходна точка е нужна. Това подобрява
                многократно производителността.

                Повечето HTTP размени на съобщения са кратки и бързи, докато TCP е създаден за дълготрайни и
                огромни трансфери на данни. Използвайки една TCP конекция, HTTP/2 може да използва по-ефикасно
                всяка една TCP конекция и също така значително да намали цялостния <b>overhead</b>, свързан с протокола.
                Още повече, използването на по-малко конекции намалява използваната памет и изчислителни ресурси.
            </p>

            <p class="note">
                <strong>Забележка:</strong><span>
                    По-малкия брой конекции е изкючително важен feature за подобряването на производителността на
                    deployments,
                    разчитащи на <a href="https://en.wikipedia.org/wiki/HTTPS">HTTPS</a>,
                    защото ще има по-малък брой TLS handshakes, които са скъпи, както и по-добро преизползване на дадена
                    сесия.
                </span>
            </p>
            </p>

            <h1 id="flow_control">9.Flow control</h1>
            <p>
                Flow control е механизъм, с който получателят на дадени ресурси може да каже "Чакай! Спри! Много бързо
                ми
                изпращаш информацията и
                аз нямам възможност да я обработвам. Забави темпото". С други думи, този, който получава HTTP
                съобщенията
                може да:
            </p>
            <ul>
                <li>е зает</li>
                <li>е подложен на голям трафик</li>
                <li>няма възможност да задели дадено количество ресурси за даден stream</li>
            </ul>

            <p>Например: </p>
            <ul>
                <li>
                    Клиентът може да е изпратил заявка за огромен video stream с висок приоритет,
                    но потребителят да е цъкнал pause на видеото. В този момент клиентът иска да спре или намали
                    потокът от данни към себе си, с цел избягване на пренос и буфериране на излишни данни.
                </li>
                <li>
                    Даден proxy server може да има бързи downstream и бавни upstream конекции и иска да регулира
                    колко бързо downstream конекциите пренасят данните, за да ги синхронизира с бързината на upstream
                    конекциите, с цел контролиране на използваните ресурси.
                </li>
                <li>
                    И други...
                </li>
            </ul>

            <p>
                Горните неща може би ви напомнят за <a
                    href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Flow_control">TCP flow control</a>
                -
                проблемът там е идентичен. Разликата обаче е, че HTTP/2 потоците се мултиплексират върху <u>една</u> TCP
                конекция,
                което затруднява регулацията на тяхния пренос.
                <br>
                HTTP/2 предоставя няколко прости елемента, които позволяват на клиента и сървъра да си имплементират
                сами
                <b>stream- и connection-level flow control:</b>
            </p>

            <ul>
                <li>
                    Всеки получател може да си избере сам <b>window size-ът</b>, който желае за отделните streams, както
                    и
                    за цялата конекция.
                </li>
                <li>
                    Flow control не може да бъде деактивиран. Когато HTTP/2 конекцията е изградена, клиентът и сървърът
                    си
                    разменят
                    <b>SETTINGS</b> frames, които определят големината на <b>flow control windows</b> в двете посоки на
                    комуникацията.
                    Стойността по подразбиране на този window е 65,535 байта, но получателят може да го set-не на
                    максималната стойност (2^31-1 байта),
                    и да го поддържа изпращайки <b>WINDOW_UPDATE</b> frame, когато получи някакви данни.
                </li>
                <li>
                    Flow control е базиран на <b>hop-by-hop</b>, а не на <b>end-to-end</b>. Тоест всички машини, през
                    които
                    минават
                    данните, докато отиват към крайната цел, могат да влияят на flow-control-ът (за разлика от
                    end-to-end,
                    където не ни интересува изобщо
                    през къде минават данните).
                </li>
            </ul>


            <p>
                HTTP/2 не използва специфичен алгоритъм за имплементацията на flow control. Той предоставя елементи,
                чрез
                които клиентът и сървърът да могат сами да си избератстратегията и алгоритъма, с който ще го
                имплементират.
                Това може да подобри както истинската производителност, така и
                <a href="https://hpbn.co/primer-on-web-performance/#speed-performance-and-human-perception">възприетата
                    от
                    човека производителност</a>.
                <br><br>
                Например application-layer flow control може да позволи на browser-а, ако иска, да си fetch-не само част
                от
                определен ресурс.
                След това ще отложи (on hold) доставката на оставащата част този ресурс, намалявайки stream flow control
                window-ът на 0. И по-късно може
                да го увеличи. С други думи, browser-ът например може да си изтегли само preview на дадена картина, да я
                покаже на потребителя и
                после да позволи на други ресурси с висок приоритет да бъдат fetch-нати. По-късно, след като
                по-критичните
                ресурси бъдат изтеглени, ще си доизтегли цялата картинка.
            </p>

            <h1 id="server_push">10. Server push</h1>
            <p>
                Друг мощен нов feature на HTTP/2 е способността на даден сървър да изпраща <b>няколко response-a</b> в
                отговор на
                <b>една клиентска заявка</b>. Тоест освен данните, които клиентът е поискал, сървърът може да push-не
                допълнителни ресурси
                към клиента, които сметне, че ще му бъдат нужни, без клиентът да ги е поискал експлицитно.
            </p>

            <img src="images/push01.svg" alt="server push" height="400" width="1000">

            <p class="note">
                <strong>Забележка:</strong><span>
                    HTTP/2 избяга от стрикната семнатика на 'one-to-one request-response' и позволи 'one-to-many
                    request-response'
                    семантика, която е инициирана от сървъра. Този нов feature ще има важни дългосрочни последици за
                    това
                    как
                    се мисли относно протокола и къде/как той ще бъде използван.
                </span>
            </p>

            <p>
                Защо бихме имали нужда от такъв механизъм в browser-a? Едно стандартно web приложение се състои от много
                ресурси,
                всички от които се октриват от клиента, анализирайки документите, които сървърът предоставя. В резултат
                на
                това,
                защо да не се елиминира ненужната латенция и не се позволи на сървъра да push-ва ресурсите, които са
                близки
                до поисканите
                от клиента, предварително? С други думи, сървърът предварително знае кои ресурси клиентът ще поиска -
                това е
                <b>server push</b>.
                <br><br>
                Push ресурсите могат да бъдат:
                <ul>
                    <li>кеширани от клиента</li>
                    <li>преизползвани в рамките на няколко различни web страници</li>
                    <li>мултиплексирани заедно с други ресурси</li>
                    <li>приоритизирани от сървъра</li>
                    <li>отказани от клиента</li>
                </ul>
            </p>

            <h1 id="push_promise_101">11. PUSH_PROMISE 101</h1>
            <p>
                Всички <b>server push streams</b> се инициират посредством <b>PUSH_PROMISE</b> frames, които
                сигнализират за
                намеренията на сървъра да push-не дадените ресурси към клиента. Тези frames трябва да бъдат push-нати
                преди
                самите ресурси.
                Това е изключително важно: клиентът трябва да знае <b>предварително</b> кои ресурси сървърът има
                намерение
                да push-не, с цел
                избягване на дуплициране на ресурси, например.
                <br><br>
                След като клиентът получи <b>PUSH_PROMISE</b> frame, той има възможността да откаже този поток
                посредством
                <b>RST_STREAM</b> frame. (Това може да се случи, ако например ресурът вече е кеширан от клиента). Това е
                важно подобрение на HTTP/1.x. Защото <i>resource inlining</i> оптимизацията, която HTTP/1.x ползва, е
                еквивалентна
                на forced push: клиентът не може да откаже push-а.
                <br><br>
                С HTTP/2 клиентът има пълен контрол над това как се използва server push механизмът. Клиентът може да
                ограничи
                броят на конкурентните push streams; може да наглася flow control window-ът за да контролира колко данни
                минават през
                даден push stream; може да деактивира server push напълно. Тези 'изисквания' на клиента се предават към
                сървъра посредством
                <b>SETTINGS</b> frame в началото на HTTP/2 конекцията и могат да бъдат update-нати по всяко едно време.
                <br><br>
                Всеки push-нат ресурс е stream, който, за разлика от inlined resource, може да бъде индивидуално
                мултиплексиран, приоритизиран
                и обработен от клиента. Единственото ограничение, свързано със сигурността, наложено от browser-a, е, че
                push-натите ресурси
                трябва да се подчиняват на т.нар. <a href="https://en.wikipedia.org/wiki/Same-origin_policy">same-origin
                    policy</a>: сървърът
                определя ресурите, които ще бъдат предоставяни.
            </p>

            <h2 id="resources">Ресурси:</h2>
            <ul>
                <a href="https://tools.ietf.org/html/rfc7540">
                    <li>https://tools.ietf.org/html/rfc7540</li>
                </a>

                <a href="https://en.wikipedia.org/wiki/HTTP/2">
                    <li>https://en.wikipedia.org/wiki/HTTP/2</li>
                </a>

                <a
                    href="https://developers.google.com/web/fundamentals/performance/http2#a_brief_history_of_spdy_and_http2">
                    <li>https://developers.google.com/web/fundamentals/performance/http2#a_brief_history_of_spdy_and_http2
                    </li>
                </a>

                <a href="https://en.wikipedia.org/wiki/HTTP_pipelining">
                    <li>https://en.wikipedia.org/wiki/HTTP_pipelining</li>
                </a>

                <a href="https://en.wikipedia.org/wiki/Head-of-line_blocking">
                    <li>https://en.wikipedia.org/wiki/Head-of-line_blocking</li>
                </a>

                <a href="https://en.wikipedia.org/wiki/Same-origin_policy>">
                    <li>https://en.wikipedia.org/wiki/Same-origin_policy</li>
                </a>
            </ul>
    </div>

</body>